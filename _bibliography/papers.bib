---
---

@string{aps = {American Physical Society,}}


@article{wu2025reinforcing,
  title={Reinforcing spatial reasoning in vision-language models with interwoven thinking and visual drawing},
  author={Wu, Junfei and Guan, Jian and Feng, Kaituo and Liu, Qiang and Wu, Shu and Wang, Liang and Wu, Wei and Tan, Tieniu},
  journal={arXiv preprint arXiv:2506.09965},
  year={2025},
  selected={true},
  preview={vilasr.pdf}
}

@article{feng2025video,
  title={Video-r1: Reinforcing video reasoning in mllms},
  author={Feng, Kaituo and Gong, Kaixiong and Li, Bohao and Guo, Zonghao and Wang, Yibing and Peng, Tianshuo and Wu, Junfei and Zhang, Xiaoying and Wang, Benyou and Yue, Xiangyu},
  journal={arXiv preprint arXiv:2503.21776},
  year={2025}
}

@inproceedings{wu2025sharp,
  title={SHARP: Steering Hallucination in LVLMs via Representation Engineering},
  author={Wu, Junfei and Ding, Yue and Liu, Guofan and Xia, Tianze and Huang, Ziyue and Sui, Dianbo and Liu, Qiang and Wu, Shu and Wang, Liang and Tan, Tieniu},
  booktitle={Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
  pages={14357--14372},
  year={2025},
  selected={true}
}

@inproceedings{chen-etal-2025-mixture-decoding,
    title = "Mixture of Decoding: An Attention-Inspired Adaptive Decoding Strategy to Mitigate Hallucinations in Large Vision-Language Models",
    author = "Chen, Xinlong  and
      Zhang, Yuanxing  and
      Liu, Qiang  and
      Wu, Junfei  and
      Zhang, Fuzheng  and
      Tan, Tieniu",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2025",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-acl.448/",
    doi = "10.18653/v1/2025.findings-acl.448",
    pages = "8525--8542",
    ISBN = "979-8-89176-256-5",
    abstract = "Large Vision-Language Models (LVLMs) have exhibited impressive capabilities across various visual tasks, yet they remain hindered by the persistent challenge of hallucinations. To address this critical issue, we propose Mixture of Decoding (MoD), a novel approach for hallucination mitigation that dynamically adapts decoding strategies by evaluating the correctness of the model{'}s attention on image tokens. Specifically, MoD measures the consistency between outputs generated from the original image tokens and those derived from the model{'}s attended image tokens, to distinguish the correctness aforementioned. If the outputs are consistent, indicating correct attention, MoD employs a complementary strategy to amplify critical information. Conversely, if the outputs are inconsistent, suggesting erroneous attention, MoD utilizes a contrastive strategy to suppress misleading information. Extensive experiments demonstrate that MoD significantly outperforms existing decoding methods across multiple mainstream benchmarks, effectively mitigating hallucinations in LVLMs. Code is available at https://github.com/xlchen0205/MoD."
}

@article{guan2025survey,
  title={A Survey on Personalized Alignment--The Missing Piece for Large Language Models in Real-World Applications},
  author={Guan, Jian and Wu, Junfei and Li, Jia-Nan and Cheng, Chuanqi and Wu, Wei},
  journal={arXiv preprint arXiv:2503.17003},
  year={2025},
  selected={true}
}

@inproceedings{zhang2025mme,
  title={MME-RealWorld: Could Your Multimodal LLM Challenge High-Resolution Real-World Scenarios that are Difficult for Humans?},
  author={Zhang, YiFan and Zhang, Huanyu and Tian, Haochen and Fu, Chaoyou and Zhang, Shuangqing and Wu, Junfei and Li, Feng and Wang, Kun and Wen, Qingsong and Zhang, Zhang and others},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}

@inproceedings{wu2024logical,
  title={Logical Closed Loop: Uncovering Object Hallucinations in Large Vision-Language Models},
  author={Wu, Junfei and Liu, Qiang and Wang, Ding and Zhang, Jinghao and Wu, Shu and Wang, Liang and Tan, Tieniu},
  booktitle={Findings of the Association for Computational Linguistics ACL 2024},
  pages={6944--6962},
  year={2024},
  selected={true},
  preview={logical_closed_loop.pdf}
}


@article{liu2024uni,
  title={Uni-modal event-agnostic knowledge distillation for multimodal fake news detection},
  author={Liu, Guofan and Zhang, Jinghao and Liu, Qiang and Wu, Junfei and Wu, Shu and Wang, Liang},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2024},
  publisher={IEEE}
}

@article{liu2024out,
  title={Out-of-distribution evidence-aware fake news detection via dual adversarial debiasing},
  author={Liu, Qiang and Wu, Junfei and Wu, Shu and Wang, Liang},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={36},
  number={11},
  pages={6801--6813},
  year={2024},
  publisher={IEEE},
  selected={true}
}


@article{wu2023adversarial,
  title={Adversarial contrastive learning for evidence-aware fake news detection with graph neural networks},
  author={Wu, Junfei and Xu, Weizhi and Liu, Qiang and Wu, Shu and Wang, Liang},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={36},
  number={11},
  pages={5591--5604},
  year={2023},
  publisher={IEEE},
  selected={true}
}

@inproceedings{wu2022bias,
  title={Bias mitigation for evidence-aware fake news detection by causal intervention},
  author={Wu, Junfei and Liu, Qiang and Xu, Weizhi and Wu, Shu},
  booktitle={Proceedings of the 45th International ACM SIGIR conference on research and development in information retrieval},
  pages={2308--2313},
  year={2022},
  selected={true}
}


@inproceedings{xu2022evidence,
  title={Evidence-aware fake news detection with graph neural networks},
  author={Xu, Weizhi and Wu, Junfei and Liu, Qiang and Wu, Shu and Wang, Liang},
  booktitle={Proceedings of the ACM web conference 2022},
  pages={2501--2510},
  selected={true},
  year={2022}
}


